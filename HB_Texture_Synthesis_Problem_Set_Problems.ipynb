{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ee6d94-883d-4385-b16d-c100f2f955db",
   "metadata": {
    "id": "62ee6d94-883d-4385-b16d-c100f2f955db"
   },
   "source": [
    "## Heeger & Bergen Texture Synthesis Algorithms\n",
    "\n",
    "The Heeger & Bergen (HB) texture synthesis algorithm is a method used to generate realistic textures. It involves analyzing the statistical properties of a given texture and then using this information to synthesize new textures with similar characteristics.\n",
    "\n",
    "The textured images in the `images` folder are from Thibaud Briand et al. “The Heeger & Bergen Pyra-\n",
    "mid Based Texture Synthesis Algorithm”. In: Image\n",
    "Processing On Line 4 (2014), pp. 276–299. DOI: 10.\n",
    "5201/ipol.2014.79."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a2eb6-cf76-450b-b738-8b87b0ff9839",
   "metadata": {
    "id": "bb6a2eb6-cf76-450b-b738-8b87b0ff9839"
   },
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bKJxtvOHDQim",
   "metadata": {
    "id": "bKJxtvOHDQim"
   },
   "outputs": [],
   "source": [
    "# !pip install pyrtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60274ac4-a497-41fa-b53f-677d8eae9650",
   "metadata": {
    "id": "60274ac4-a497-41fa-b53f-677d8eae9650"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import pyrtools as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import factorial\n",
    "import math\n",
    "from pyrtools.pyramids.c.wrapper import pointOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c1cfc-6b48-4311-8663-725078cc719b",
   "metadata": {
    "id": "376c1cfc-6b48-4311-8663-725078cc719b"
   },
   "source": [
    "## Q1.1 Given an image, contruct it's steerable pyramids representation\n",
    "\n",
    "A steerable pyramid is a multi-resolution image representation that can be efficiently computed and analyzed. It is particularly useful for capturing and decomposing image information at different scales and orientations. The construction of a steerable pyramid involves applying a series of filtering and downsampling operations, often using filters that are steerable in different directions.\n",
    "\n",
    "For $P$ scales, and $Q$ orientations of an image, a steerable pyramid representation has a total of $PQ + 2$ filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D7aOmUoktIdn",
   "metadata": {
    "id": "D7aOmUoktIdn"
   },
   "source": [
    "Consult the `pyrtools` documentation for creating the `steerable_pyramid_representation` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa05cb2-a95e-4531-b9d7-51c24e2790fc",
   "metadata": {
    "id": "7aa05cb2-a95e-4531-b9d7-51c24e2790fc"
   },
   "outputs": [],
   "source": [
    "def steerable_pyramid_representation(image, P, Q):\n",
    "    \"\"\"\n",
    "    Computes the steerable pyramid representation of an image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: 2D array, input image\n",
    "    - P: int, number of scales\n",
    "    - Q: int, number of orientations\n",
    "\n",
    "    Returns:\n",
    "    - pyr_coeffs: dictionary, coefficients of the steerable pyramid\n",
    "    - pyr_sizes: dictionary, sizes of the pyramid levels\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf6163-c95c-4735-b30f-a36f6411b06c",
   "metadata": {
    "id": "7ecf6163-c95c-4735-b30f-a36f6411b06c"
   },
   "source": [
    "### Test Steerable Pyramid Representation\n",
    "\n",
    "Test the steerable pyramid representation using `images/paperwall.jpeg` by plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6569ee2-d2c2-4928-8c78-463dbfcca904",
   "metadata": {
    "id": "a6569ee2-d2c2-4928-8c78-463dbfcca904"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39e514-a282-4356-8f26-6853cbe5c993",
   "metadata": {
    "id": "af39e514-a282-4356-8f26-6853cbe5c993"
   },
   "source": [
    "## Q1.2 Given a steerable pyramid representation of an image, reconstruct the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-7IzLgpItTZ_",
   "metadata": {
    "id": "-7IzLgpItTZ_"
   },
   "source": [
    "Since the steerable pyramid is designed to be self-inverting, we can reconstruct an image from its pyramid using the same filters employed in the decomposition process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VEpIdlomtnHC",
   "metadata": {
    "id": "VEpIdlomtnHC"
   },
   "source": [
    "Consult the `pyrtools` documentation for creating the `reconstruct` function. Test the `reconstruct` function using the texturized image `images/paperwall.jpeg` by plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd21dc4-0398-4422-a1af-3ed4257e4f06",
   "metadata": {
    "id": "0cd21dc4-0398-4422-a1af-3ed4257e4f06"
   },
   "outputs": [],
   "source": [
    "def reconstruct_image(pyr_coeffs, pyr_sizes):\n",
    "    \"\"\"\n",
    "    Computes the reoncsturcted image using the coefficients of the steerable pyramid.\n",
    "\n",
    "    Parameters:\n",
    "    - pyr_coeffs: dictionary, coefficients of the steerable pyramid\n",
    "    - pyr_sizes: dictionary, sizes of the pyramid levels\n",
    "\n",
    "    Returns:\n",
    "    reconstructed_image\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0daa8b7-6c5b-46a5-9a7f-bad8f1551990",
   "metadata": {
    "id": "c0daa8b7-6c5b-46a5-9a7f-bad8f1551990"
   },
   "source": [
    "### Test Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf0d9f-6ae1-4b77-9a9e-e862ac4c6884",
   "metadata": {
    "id": "fadf0d9f-6ae1-4b77-9a9e-e862ac4c6884"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abe3ca-7d99-46c3-b93b-6be9645f0cc3",
   "metadata": {
    "id": "c5abe3ca-7d99-46c3-b93b-6be9645f0cc3"
   },
   "source": [
    "## Q2. Histogram Matching Function\n",
    "\n",
    "Histogram matching is used to adjust the color distribution of an image to match a specified histogram. In this context, the histogram denotes the spread of pixel intensities. It is important to note that histogram matching is an ill-posed problem due to the absence of a unique solution. This arises from the fact that different images can possess similar or identical histograms, leading to ambiguity in determining a unique solution.\n",
    "\n",
    "### Algorithm: Histogram Matching\n",
    "\n",
    "**Input:** Input image $u$, reference image $v$ (both images have size $M \\times N$)\n",
    "\n",
    "**Output:** Image $u$ having the same histogram as $v$ (the input $u$ is lost)\n",
    "\n",
    "1. Define $L = MN$ and describe the images as vectors of length $L$ (e.g., by reading values line by line).\n",
    "2. Sort the reference image $v$:\n",
    "3. Determine the permutation $\\tau$ such that $v_{\\tau(1)} \\leq v_{\\tau(2)} \\leq \\ldots \\leq v_{\\tau(L)}$.\n",
    "4. Sort the input image $u$:\n",
    "5. Determine the permutation $\\sigma$ such that$u_{\\sigma(1)} \\leq u_{\\sigma(2)} \\leq \\ldots \\leq u_{\\sigma(L)}$.\n",
    "6. Match the histogram of $u$:\n",
    "   - for rank$k = 1$ to $L$ do\n",
    "     - $u_{\\sigma(k)} \\leftarrow v_{\\tau(k)}$(the $k$-th pixel of $u$ takes the gray-value of the $k$-th pixel of $v$).\n",
    "   - end\n",
    "\n",
    "\n",
    "\n",
    "Given an input image $u$ and a reference image $v$ of the same size, histogram matching consists in changing the gray-level values of the input $u$ so that it gets the same histogram as the reference image $v$. Complete the `histogram_matching` function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca09ab-807e-470f-9d7b-45f934c54402",
   "metadata": {
    "id": "5eca09ab-807e-470f-9d7b-45f934c54402"
   },
   "outputs": [],
   "source": [
    "def histogram_matching(v, u):\n",
    "    \"\"\"\n",
    "    Aligns the image u onto the histogram of the reference image v.\n",
    "\n",
    "    Parameters:\n",
    "    - v: Reference image\n",
    "    - u: Input image to be modified\n",
    "\n",
    "    Returns:\n",
    "    - Modified image u with aligned histogram\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3056280-c275-4b55-8136-0c1096f8cb7e",
   "metadata": {
    "id": "e3056280-c275-4b55-8136-0c1096f8cb7e"
   },
   "source": [
    "## Q3. Histogram Matching Function for scaled images\n",
    "\n",
    "\n",
    "The above function aligns histograms when the image u and reference image v have the same shape. Often, we would expect the synthesized texture to be much larger than the reference texture in texture synthesis. In this case number of pixels in synthesized image and input texture image are not the same. Adapt the histogram matching function for scaled images.\n",
    "\n",
    "Consider an image $u$ which is magnified by (`width_scale`, `height_scale`) compared to image $u$ on width and height dimensions. How can the histogram matching function be modified to effectively operate with images of different scales?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fb0d5-7d24-47fc-b478-d21a9c5fca47",
   "metadata": {
    "id": "c03fb0d5-7d24-47fc-b478-d21a9c5fca47"
   },
   "outputs": [],
   "source": [
    "def histogram_matching_scaled(v, u, width_scale, height_scale):\n",
    "    # TODO:\n",
    "    # Hint: Calculate the scaling factor for the number of pixels in u compared to v\n",
    "    factor_scale = None\n",
    "\n",
    "    # Return the modified u after histogram matching\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f5b4f-fbce-40f1-8476-27a5a45ca6ee",
   "metadata": {
    "id": "f28f5b4f-fbce-40f1-8476-27a5a45ca6ee"
   },
   "source": [
    "## Q4. Heeger Bergen Texture Synthesis Algorithm\n",
    "\n",
    "We can now present the texture synthesis algorithm developed by Heeger and Bergen. Starting from a white noise image, histogram matchings are performed to the texture image alternatively in the image domain and in the steerable pyramid domain. After a few iterations, all the output histograms will match the ones of the input texture, and thus, the output texture will be visually similar to the input texture. The pseudo code of the algorithm is detailed below.\n",
    "\n",
    "### Algorithm: Heeger-Bergen Texture Synthesis Algorithm for Grayscale Images (without extension)\n",
    "\n",
    "**Input:**\n",
    "- Number of scales P\n",
    "- Number of orientations Q\n",
    "- Texture image u of size M × N (where M and N are multiples of 2^P)\n",
    "- Number of iterations Niter\n",
    "\n",
    "**Output:**\n",
    "- Texture image v of size M × N\n",
    "\n",
    "1. **Input Analysis:**\n",
    "    - Compute and store the steerable pyramid with P scales and Q orientations of the input texture u.\n",
    "\n",
    "2. **Output Synthesis:**\n",
    "    - Initialize v with a Gaussian white noise.\n",
    "    - Match the gray-level histogram of v with the gray-level histogram of the input u.\n",
    "\n",
    "3. **Iteration Loop:**\n",
    "    ```\n",
    "    for iteration i = 1 to Niter do\n",
    "    ```\n",
    "    - Compute the steerable pyramid of v.\n",
    "    - For each of the P Q + 2 images of this pyramid, apply histogram matching with the corresponding image of the pyramid of u.\n",
    "    - Apply the image reconstruction algorithm to this new histogram-matched pyramid and store the obtained image in v.\n",
    "    - Match the gray-level histogram of v with the gray-level histogram of the input u.\n",
    "\n",
    "4. **Return Result:**\n",
    "    ```\n",
    "    end\n",
    "    Return v.\n",
    "    ```\n",
    "\n",
    "Complete the `heeger_bergen_texture_synthesis` algorithm, which takes in:\n",
    "- A reference texture `texture`\n",
    "- Number of scales `P`\n",
    "- Number of orientations `Q` for steerable pyramid representation\n",
    "- `Niter` number of iterations\n",
    "- `width_scale` and `height_scale` denoting how much we want to magnify the synthesized texture by.\n",
    "\n",
    "Test the function by synthesizing for all images found in the `images` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e48395-ea20-4ba8-9cc3-24375c8bb3fe",
   "metadata": {
    "id": "85e48395-ea20-4ba8-9cc3-24375c8bb3fe"
   },
   "outputs": [],
   "source": [
    "def heeger_bergen_texture_synthesis(texture, P, Q, Niter, width_scale=1, height_scale=1):\n",
    "    \"\"\"\n",
    "    Heeger-Bergen Texture Synthesis Algorithm for Grayscale Images.\n",
    "\n",
    "    Parameters:\n",
    "    - texture: Reference texture image\n",
    "    - P: Number of scales\n",
    "    - Q: Number of orientations for steerable pyramid representation\n",
    "    - Niter: Number of iterations\n",
    "    - width_scale: Magnification factor for width (default is 1)\n",
    "    - height_scale: Magnification factor for height (default is 1)\n",
    "\n",
    "    Returns:\n",
    "    - Synthesized texture image\n",
    "    \"\"\"\n",
    "    # Input analysis\n",
    "    # TODO\n",
    "\n",
    "    # Output synthesis\n",
    "    # TODO\n",
    "\n",
    "    # Iteration Loop\n",
    "    # TODO\n",
    "\n",
    "    # Return synthesized texture image\n",
    "    # TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f7db2-dc91-4eec-a17d-9829579ae598",
   "metadata": {
    "id": "042f7db2-dc91-4eec-a17d-9829579ae598"
   },
   "source": [
    "### Synthesize textures for all references images (with same shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d97ec1-5b81-4cac-8bca-03885cd7c95b",
   "metadata": {
    "id": "70d97ec1-5b81-4cac-8bca-03885cd7c95b"
   },
   "outputs": [],
   "source": [
    "# TODO: Test with all images in images folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e27503-4a7c-4cac-a43d-f32ca2327909",
   "metadata": {
    "id": "22e27503-4a7c-4cac-a43d-f32ca2327909"
   },
   "source": [
    "### Synthesize textures for all references images with magnified shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474b589-48dc-431e-a1d0-7e608b92c05d",
   "metadata": {
    "id": "d474b589-48dc-431e-a1d0-7e608b92c05d"
   },
   "outputs": [],
   "source": [
    "# TODO: Test with all images in images folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c841b-4aec-4a08-9f3a-c711037c2f23",
   "metadata": {
    "id": "3c5c841b-4aec-4a08-9f3a-c711037c2f23"
   },
   "source": [
    "## Q5 Extending HB Texture Synthesis to Color Space\n",
    "\n",
    "**Question** The Heeger-Bergen algorithm relies on histogram matching, making it well-defined only for grayscale images. How can we extend it to color spaces? Is it possible to run texture synthesis independently on each color and then combine the results? Why or why not? Try testing with the color textured image `images/stainedfur.jpeg`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282915c-20b6-4038-8ce7-222e303904d0",
   "metadata": {
    "id": "6282915c-20b6-4038-8ce7-222e303904d0"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LEU1Mia-BVrU",
   "metadata": {
    "id": "LEU1Mia-BVrU"
   },
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60633c75-8002-4710-ba6e-4c0947a17f30",
   "metadata": {
    "id": "60633c75-8002-4710-ba6e-4c0947a17f30"
   },
   "source": [
    "The Heeger-Bergen texture synthesis algorithm for RGB color textures is the following:\n",
    "1. Compute the PCA color space of the input image $u$.\n",
    "2. Determine the channels of $u$ in the PCA color space.\n",
    "3. Apply the texture synthesis algorithm implemented above on each PCA channel. This gives an output texture $v$ in the PCA color space.\n",
    "4. Convert the image $v$ in the RGB color space by applying the procedure described above. The obtained RGB image is the output of the algorithm.\n",
    "\n",
    "Complete the `heeger_bergen_texture_synthesis_color` function with the above Heeger-Bergen texture synthesis for RGB color textures, consulting the documentation for `PCA` found in `sklearn.decomposition`. Test the function using the color textured image in `images/stainedfur.jpeg` by plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd360e-e6f8-420b-a14e-c52167061d99",
   "metadata": {
    "id": "5cdd360e-e6f8-420b-a14e-c52167061d99"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def heeger_bergen_texture_synthesis_color(image, P, Q, Niter, width_scale=1, height_scale=1):\n",
    "    # TODO\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0c3fb-7d34-4447-9afd-e5009e90b1b5",
   "metadata": {
    "id": "bda0c3fb-7d34-4447-9afd-e5009e90b1b5"
   },
   "source": [
    "## Q6. Edge Blending - Mirror Symmetrization\n",
    "\n",
    "In the real world, textures are never periodic. However, the pyramid decomposition, which is based on the Discrete Fourier Transform (DFT) that treats input images as periodic, introduces discontinuity in handling edges. A simple method to address this issue is to use mirror symmetrization at the borders. Construct a mirror symmetrization function and test it using the image `images/randomwood.jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ee00d-4f21-48f2-bb4c-19ae3f92a1ba",
   "metadata": {
    "id": "283ee00d-4f21-48f2-bb4c-19ae3f92a1ba"
   },
   "outputs": [],
   "source": [
    "def edge_handling_mirror_symmetrization(image):\n",
    "    # TODO: Consult the comments for getting started\n",
    "\n",
    "    # Get the width and height of the input image\n",
    "\n",
    "    # Create an empty array for the mirrored image with double the width and height\n",
    "\n",
    "    # Mirror symmetrization loop\n",
    "            # Top-left quadrant\n",
    "            # Top-right quadrant\n",
    "            # Bottom-left quadrant\n",
    "            # Bottom-right quadrant\n",
    "\n",
    "    # Generate steerable pyramid representation for the original and mirrored images\n",
    "\n",
    "\n",
    "    # Adjust the mirrored pyramid coefficients to match the original image size\n",
    "\n",
    "    # Reconstruct the image from the modified pyramid coefficients\n",
    "\n",
    "    # Return the reconstructed image\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b27b2-08cc-414d-af97-af8494dc08ed",
   "metadata": {
    "id": "e70b27b2-08cc-414d-af97-af8494dc08ed"
   },
   "source": [
    "## Q7. Edge Blending - Periodic Component\n",
    "\n",
    "In Q6, we explored how to handle edges using mirror symmetrization. Although mirror symmetrization ensures continuity at the borders, it is not perfect, as it introduces artificial orientations in the input texture. Therefore, we will explore another edge handling method: replacing the input texture with its periodic component.\n",
    "\n",
    "\n",
    "\n",
    "1. Compute the discrete Laplacian $\\Delta_i u$ of $u$.\n",
    "2. Compute the DFT $\\widehat{\\Delta_i u}$ of $\\Delta_i u$.\n",
    "3. Compute the DFT $\\hat{p}$ of $p$ by inverting the discrete periodic Laplacian:\n",
    "\n",
    "$$\n",
    "\\hat{p}_{m,n} =\n",
    "\\begin{cases}\n",
    "(4 - 2 \\cos(\\frac{2m\\pi}{M}) - 2 \\cos(\\frac{2n\\pi}{N}))^{-1} \\widehat{\\Delta_i u}_{m,n}, & \\text{if } (m,n) \\in \\hat{\\Omega}_{M,N} \\setminus \\{(0,0)\\} \\\\\n",
    "\\hat{p}_{0,0} = \\sum_{k=0}^{M-1} \\sum_{l=0}^{N-1} u_{k,l}, & \\text{if } (m,n) = (0,0)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "4. Compute $p$ by inverse DFT.\n",
    "\n",
    "Use `images/randomwood.jpeg` to test the periodic component function following the above steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c823b1f-d688-4d27-b3b4-5610cdcfcb99",
   "metadata": {
    "id": "5c823b1f-d688-4d27-b3b4-5610cdcfcb99"
   },
   "outputs": [],
   "source": [
    "def compute_p_hat(image, image_laplacian_dft):\n",
    "    \"\"\"\n",
    "    Compute the function p_hat for given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - M, N: Size of the 2D grid.\n",
    "    - omega: Set of excluded coordinates (m, n) as a list of tuples.\n",
    "    - uk: 2D array representing the input grid.\n",
    "\n",
    "    Returns:\n",
    "    - p_hat: Resulting 2D array.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return None\n",
    "\n",
    "\n",
    "def edge_handling_periodic_component(image):\n",
    "    # TODO: Compute the Laplacian using the cv2.Laplacian function\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d6b7b-ec8e-4c04-a3b3-8d91b7d588f9",
   "metadata": {
    "id": "6f6d6b7b-ec8e-4c04-a3b3-8d91b7d588f9"
   },
   "outputs": [],
   "source": [
    "# TODO: Test by plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sY2nVB6YxKIc",
   "metadata": {
    "id": "sY2nVB6YxKIc"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93920bfa-5483-45f8-bae3-86b968b02fd8",
   "metadata": {
    "id": "93920bfa-5483-45f8-bae3-86b968b02fd8"
   },
   "source": [
    "## Reference Steerable Pyramid Representation\n",
    "\n",
    "The following code implements the steerable pyramid representation of an image. The code begins by preparing the image, creating coordinate grids, and computing various mathematical transformations like angle and log-polar coordinates. It then applies high-pass and low-pass filters to extract different frequency components of the image.\n",
    "\n",
    "The code iterates over multiple scales, at each step computing bandpass filters for various orientations to capture different directional details, which is achieved through using Fourier transforms. The code returns a collection of coefficients stored in a dictionary representing the original image at various scales and orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7bbd4-3405-44dd-bbd4-12feffbd6c24",
   "metadata": {
    "id": "22b7bbd4-3405-44dd-bbd4-12feffbd6c24"
   },
   "outputs": [],
   "source": [
    "def rcosFn(width=1, position=0, values=(0, 1)):\n",
    "    # Define the number of points in the waveform\n",
    "    sz = 256   # arbitrary!\n",
    "    # Generate a time vector with values between -pi and 2*pi\n",
    "    X = np.pi * np.arange(-sz - 1, 2) / (2 * sz)\n",
    "    # Generate the raised cosine waveform using the specified values\n",
    "    Y = values[0] + (values[1] - values[0]) * np.cos(X) ** 2\n",
    "    # Set the boundary values to ensure continuity\n",
    "    Y[0] = Y[1]\n",
    "    Y[sz + 2] = Y[sz + 1]\n",
    "    # Adjust the position and width of the waveform\n",
    "    X = position + (2 * width / np.pi) * (X + np.pi / 4)\n",
    "    # Return the time vector (X) and the corresponding waveform (Y)\n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "def steerable_pyramid_representation(image, P, Q):\n",
    "    \"\"\"\n",
    "    Computes the steerable pyramid representation of an image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: 2D array, input image\n",
    "    - P: int, number of scales\n",
    "    - Q: int, number of orientations\n",
    "\n",
    "    Returns:\n",
    "    - pyr_coeffs: dictionary, coefficients of the steerable pyramid\n",
    "    - pyr_sizes: dictionary, sizes of the pyramid levels\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize dictionaries to store pyramid coefficients and sizes\n",
    "    pyr_coeffs = {}\n",
    "    pyr_sizes = {}\n",
    "\n",
    "    # Number of scales and orientations\n",
    "    num_scales = P\n",
    "    num_orientations = Q + 1\n",
    "\n",
    "    # Width of the transition function\n",
    "    twidth = 1\n",
    "\n",
    "    # Dimensions of the input image\n",
    "    dims = np.array(image.shape)\n",
    "\n",
    "    # Center of the image\n",
    "    ctr = np.ceil((np.array(dims) + 0.5) / 2).astype(int)\n",
    "\n",
    "    # Create coordinate grids\n",
    "    (xramp, yramp) = np.meshgrid(np.linspace(-1, 1, dims[1]+1)[:-1],\n",
    "                                 np.linspace(-1, 1, dims[0]+1)[:-1])\n",
    "\n",
    "    # Compute angle and log-polar coordinates\n",
    "    angle = np.arctan2(yramp, xramp)\n",
    "    log_rad = np.sqrt(xramp ** 2 + yramp ** 2)\n",
    "    log_rad[ctr[0] - 1, ctr[1] - 1] = log_rad[ctr[0] - 1, ctr[1] - 2]\n",
    "    log_rad = np.log2(log_rad)\n",
    "\n",
    "    # Radial transition function (a raised cosine in log-frequency)\n",
    "    (Xrcos, Yrcos) = rcosFn(twidth, (-twidth / 2.0), np.array([0, 1]))\n",
    "    Yrcos = np.sqrt(Yrcos)\n",
    "    YIrcos = np.sqrt(1.0 - Yrcos**2)\n",
    "    lo0mask = pointOp(log_rad, YIrcos, Xrcos[0], Xrcos[1]-Xrcos[0])\n",
    "\n",
    "    # Compute the Fourier transform of the input image\n",
    "    imdft = np.fft.fftshift(np.fft.fft2(image))\n",
    "\n",
    "    # High-pass filter the image\n",
    "    hi0mask = pointOp(log_rad, Yrcos, Xrcos[0], Xrcos[1] - Xrcos[0])\n",
    "    hi0dft = imdft * hi0mask.reshape(imdft.shape[0], imdft.shape[1])\n",
    "    hi0 = np.fft.ifft2(np.fft.ifftshift(hi0dft))\n",
    "\n",
    "    # Store the high-pass residual\n",
    "    pyr_coeffs['residual_highpass'] = np.real(hi0)\n",
    "    pyr_sizes['residual_highpass'] = hi0.shape\n",
    "\n",
    "    # Low-pass filter the image\n",
    "    lo0mask = lo0mask.reshape(imdft.shape[0], imdft.shape[1])\n",
    "    lodft = imdft * lo0mask\n",
    "\n",
    "    # Iterate over scales\n",
    "    for i in range(num_scales):\n",
    "        Xrcos -= np.log2(2)\n",
    "\n",
    "        # Generate lookup table for cosine values\n",
    "        lutsize = 1024\n",
    "        Xcosn = np.pi * np.arange(-(2 * lutsize + 1), (lutsize + 2)) / lutsize\n",
    "\n",
    "        # Compute steerable filters' coefficients\n",
    "        const = (2 **( 2 * Q)) * (factorial(Q, exact=True) ** 2)/ float(num_orientations * factorial(2 * Q, exact=True))\n",
    "        Ycosn = np.sqrt(const) * (np.cos(Xcosn)) ** Q\n",
    "\n",
    "        # Compute the frequency masks\n",
    "        log_rad_test = np.reshape(log_rad, (1, log_rad.shape[0] * log_rad.shape[1]))\n",
    "        himask = pointOp(log_rad_test, Yrcos, Xrcos[0], Xrcos[1]-Xrcos[0])\n",
    "        himask = himask.reshape((lodft.shape[0], lodft.shape[1]))\n",
    "\n",
    "        # Compute angle masks\n",
    "        anglemasks = []\n",
    "        for b in range(num_orientations):\n",
    "            angle_tmp = np.reshape(angle, (1, angle.shape[0] * angle.shape[1]))\n",
    "            anglemask = pointOp(angle_tmp, Ycosn, Xcosn[0] + np.pi * b / num_orientations, Xcosn[1] - Xcosn[0])\n",
    "\n",
    "            anglemask = anglemask.reshape(lodft.shape[0], lodft.shape[1])\n",
    "            anglemasks.append(anglemask)\n",
    "\n",
    "            # Compute bandpass filter in the Fourier domain\n",
    "            banddft = (-1j) ** Q * lodft * anglemask * himask\n",
    "            band = np.fft.ifft2(np.fft.ifftshift(banddft))\n",
    "\n",
    "            # Store the bandpass coefficients\n",
    "            pyr_coeffs[(i, b)] = np.real(band.copy())\n",
    "            pyr_sizes[(i, b)] = band.shape\n",
    "\n",
    "        # Update dimensions for the next scale\n",
    "        dims = np.array(lodft.shape)\n",
    "        ctr = np.ceil((dims+0.5)/2).astype(int)\n",
    "        lodims = np.ceil((dims-0.5)/2).astype(int)\n",
    "        loctr = np.ceil((lodims+0.5)/2).astype(int)\n",
    "        lostart = ctr - loctr\n",
    "        loend = lostart + lodims\n",
    "\n",
    "        # Update log_rad, angle, and lodft for the next scale\n",
    "        log_rad = log_rad[lostart[0]:loend[0], lostart[1]:loend[1]]\n",
    "        angle = angle[lostart[0]:loend[0], lostart[1]:loend[1]]\n",
    "        lodft = lodft[lostart[0]:loend[0], lostart[1]:loend[1]]\n",
    "\n",
    "        # Update low-pass masks\n",
    "        YIrcos = np.abs(np.sqrt(1.0 - Yrcos**2))\n",
    "        log_rad_tmp = np.reshape(log_rad, (1, log_rad.shape[0] * log_rad.shape[1]))\n",
    "        lomask = pointOp(log_rad_tmp, YIrcos, Xrcos[0], Xrcos[1]-Xrcos[0])\n",
    "        lomask = lomask.reshape(lodft.shape[0], lodft.shape[1])\n",
    "\n",
    "        lodft = lodft * lomask\n",
    "\n",
    "    # Inverse Fourier transform of the final low-pass residual\n",
    "    lodft = np.fft.ifft2(np.fft.ifftshift(lodft))\n",
    "\n",
    "    # Store the final low-pass residual coefficients\n",
    "    pyr_coeffs['residual_lowpass'] = np.real(np.array(lodft).copy())\n",
    "    pyr_sizes['residual_lowpass'] = lodft.shape\n",
    "\n",
    "    return pyr_coeffs, pyr_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8afc1-3692-4cd8-aae1-d30e4b7f95a7",
   "metadata": {
    "id": "dae8afc1-3692-4cd8-aae1-d30e4b7f95a7"
   },
   "source": [
    "## Reference: Reconstructing Image from steerable pyramid representation\n",
    "\n",
    "\n",
    "The following code reconstructs an image from its steerable pyramid representation. The code begins by identifying key parameters, such as the number of scales and orientations, based on the provided pyramid coefficients. It then proceeds to create coordinate grids, calculate angles, and determine log-polar coordinates. The reconstruction process involves applying a series of filters—high-pass, low-pass, and bandpass—at different scales and orientations. These filters capture and reconstruct the various frequency components and directional details of the image from its pyramid representation. Finally, the code combines all these filtered components using Fourier transforms to reconstruct the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdc9f3-e785-4926-9acf-8a23af555e25",
   "metadata": {
    "id": "32cdc9f3-e785-4926-9acf-8a23af555e25"
   },
   "outputs": [],
   "source": [
    "def reconstruct_image(pyr_coeffs, pyr_sizes):\n",
    "\n",
    "    recon_keys = list(pyr_coeffs.keys())\n",
    "\n",
    "    P = max([key[0] for key in recon_keys if type(key) is tuple]) + 1\n",
    "    Q = max([key[1] for key in recon_keys if type(key) is tuple])\n",
    "    num_scales = P\n",
    "    num_orientations = Q + 1\n",
    "\n",
    "    # make list of dims and bounds\n",
    "    bound_list = []\n",
    "    dim_list = []\n",
    "    # we go through pyr_sizes from smallest to largest\n",
    "    for dims in sorted(pyr_sizes.values()):\n",
    "        if dims in dim_list:\n",
    "            continue\n",
    "        dim_list.append(dims)\n",
    "        dims = np.array(dims)\n",
    "        ctr = np.ceil((dims+0.5)/2).astype(int)\n",
    "        lodims = np.ceil((dims-0.5)/2).astype(int)\n",
    "        loctr = np.ceil((lodims+0.5)/2).astype(int)\n",
    "        lostart = ctr - loctr\n",
    "        loend = lostart + lodims\n",
    "        bounds = (lostart[0], lostart[1], loend[0], loend[1])\n",
    "        bound_list.append(bounds)\n",
    "    bound_list.append((0, 0, dim_list[-1][0], dim_list[-1][1]))\n",
    "    dim_list.append((dim_list[-1][0], dim_list[-1][1]))\n",
    "\n",
    "    # matlab code starts here\n",
    "    dims = np.array(pyr_sizes['residual_highpass'])\n",
    "    ctr = np.ceil((dims+0.5)/2.0).astype(int)\n",
    "\n",
    "    (xramp, yramp) = np.meshgrid((np.arange(1, dims[1]+1)-ctr[1]) / (dims[1]/2.),\n",
    "                                 (np.arange(1, dims[0]+1)-ctr[0]) / (dims[0]/2.))\n",
    "    angle = np.arctan2(yramp, xramp)\n",
    "    log_rad = np.sqrt(xramp**2 + yramp**2)\n",
    "    log_rad[ctr[0]-1, ctr[1]-1] = log_rad[ctr[0]-1, ctr[1]-2]\n",
    "    log_rad = np.log2(log_rad)\n",
    "\n",
    "    # Radial transition function (a raised cosine in log-frequency):\n",
    "    (Xrcos, Yrcos) = rcosFn(1, (-1/2.0), np.array([0, 1]))\n",
    "    Yrcos = np.sqrt(Yrcos)\n",
    "    YIrcos = np.sqrt(1.0 - Yrcos**2)\n",
    "\n",
    "    # from reconSFpyrLevs\n",
    "    lutsize = 1024\n",
    "\n",
    "    Xcosn = np.pi * np.arange(-(2*lutsize+1), (lutsize+2)) / lutsize\n",
    "\n",
    "    const = (2**(2*Q))*(factorial(Q, exact=True)**2) / float(num_orientations*factorial(2*Q, exact=True))\n",
    "    Ycosn = np.sqrt(const) * (np.cos(Xcosn))**Q\n",
    "\n",
    "    # lowest band\n",
    "    # initialize reconstruction\n",
    "    if 'residual_lowpass' in recon_keys:\n",
    "        nresdft = np.fft.fftshift(np.fft.fft2(pyr_coeffs['residual_lowpass']))\n",
    "    else:\n",
    "        nresdft = np.zeros_like(pyr_coeffs['residual_lowpass'])\n",
    "    resdft = np.zeros(dim_list[1]) + 0j\n",
    "\n",
    "    bounds = (0, 0, 0, 0)\n",
    "    for idx in range(len(bound_list)-2, 0, -1):\n",
    "        diff = (bound_list[idx][2]-bound_list[idx][0],\n",
    "                bound_list[idx][3]-bound_list[idx][1])\n",
    "        bounds = (bounds[0]+bound_list[idx][0], bounds[1]+bound_list[idx][1],\n",
    "                  bounds[0]+bound_list[idx][0] + diff[0],\n",
    "                  bounds[1]+bound_list[idx][1] + diff[1])\n",
    "        Xrcos -= np.log2(2.0)\n",
    "    nlog_rad = log_rad[bounds[0]:bounds[2], bounds[1]:bounds[3]]\n",
    "\n",
    "    nlog_rad_tmp = np.reshape(nlog_rad, (1, nlog_rad.shape[0]*nlog_rad.shape[1]))\n",
    "    lomask = pointOp(nlog_rad_tmp, YIrcos, Xrcos[0], Xrcos[1]-Xrcos[0])\n",
    "    lomask = lomask.reshape(nresdft.shape[0], nresdft.shape[1])\n",
    "    lomask = lomask + 0j\n",
    "    resdft[bound_list[1][0]:bound_list[1][2],\n",
    "           bound_list[1][1]:bound_list[1][3]] = nresdft * lomask\n",
    "\n",
    "    # middle bands\n",
    "    for idx in range(1, len(bound_list)-1):\n",
    "        bounds1 = (0, 0, 0, 0)\n",
    "        bounds2 = (0, 0, 0, 0)\n",
    "        for boundIdx in range(len(bound_list) - 1, idx - 1, -1):\n",
    "            diff = (bound_list[boundIdx][2]-bound_list[boundIdx][0],\n",
    "                    bound_list[boundIdx][3]-bound_list[boundIdx][1])\n",
    "            bound2tmp = bounds2\n",
    "            bounds2 = (bounds2[0]+bound_list[boundIdx][0],\n",
    "                       bounds2[1]+bound_list[boundIdx][1],\n",
    "                       bounds2[0]+bound_list[boundIdx][0] + diff[0],\n",
    "                       bounds2[1]+bound_list[boundIdx][1] + diff[1])\n",
    "            bounds1 = bound2tmp\n",
    "        nlog_rad1 = log_rad[bounds1[0]:bounds1[2], bounds1[1]:bounds1[3]]\n",
    "        nlog_rad2 = log_rad[bounds2[0]:bounds2[2], bounds2[1]:bounds2[3]]\n",
    "        dims = dim_list[idx]\n",
    "        nangle = angle[bounds1[0]:bounds1[2], bounds1[1]:bounds1[3]]\n",
    "        YIrcos = np.abs(np.sqrt(1.0 - Yrcos**2))\n",
    "        if idx > 1:\n",
    "            Xrcos += np.log2(2.0)\n",
    "            nlog_rad2_tmp = np.reshape(nlog_rad2, (1, nlog_rad2.shape[0]*nlog_rad2.shape[1]))\n",
    "            lomask = pointOp(nlog_rad2_tmp, YIrcos, Xrcos[0],\n",
    "                             Xrcos[1]-Xrcos[0])\n",
    "            lomask = lomask.reshape(bounds2[2]-bounds2[0],\n",
    "                                    bounds2[3]-bounds2[1])\n",
    "            lomask = lomask + 0j\n",
    "            nresdft = np.zeros(dim_list[idx]) + 0j\n",
    "            nresdft[bound_list[idx][0]:bound_list[idx][2],\n",
    "                    bound_list[idx][1]:bound_list[idx][3]] = resdft * lomask\n",
    "            resdft = nresdft.copy()\n",
    "\n",
    "        # reconSFpyrLevs\n",
    "        if idx != 0 and idx != len(bound_list)-1:\n",
    "            for b in range(num_orientations):\n",
    "                nlog_rad1_tmp = np.reshape(nlog_rad1,\n",
    "                                           (1, nlog_rad1.shape[0]*nlog_rad1.shape[1]))\n",
    "                himask = pointOp(nlog_rad1_tmp, Yrcos, Xrcos[0], Xrcos[1]-Xrcos[0])\n",
    "\n",
    "                himask = himask.reshape(nlog_rad1.shape)\n",
    "                nangle_tmp = np.reshape(nangle, (1, nangle.shape[0]*nangle.shape[1]))\n",
    "                anglemask = pointOp(nangle_tmp, Ycosn,\n",
    "                                    Xcosn[0]+np.pi*b/num_orientations,\n",
    "                                    Xcosn[1]-Xcosn[0])\n",
    "\n",
    "                anglemask = anglemask.reshape(nangle.shape)\n",
    "                # either the coefficients will already be real-valued (if\n",
    "                # self.is_complex=False) or complex (if self.is_complex=True). in the\n",
    "                # former case, this np.real() does nothing. in the latter, we want to only\n",
    "                # reconstruct with the real portion\n",
    "                curLev = num_scales-1 - (idx-1)\n",
    "                band = np.real(pyr_coeffs[(curLev, b)])\n",
    "                if (curLev, b) in recon_keys:\n",
    "                    banddft = np.fft.fftshift(np.fft.fft2(band))\n",
    "                else:\n",
    "                    banddft = np.zeros(band.shape)\n",
    "                resdft += ((np.power(-1+0j, 0.5))**(num_orientations-1) *\n",
    "                           banddft * anglemask * himask)\n",
    "\n",
    "    # apply lo0mask\n",
    "    Xrcos += np.log2(2.0)\n",
    "    lo0mask = pointOp(log_rad, YIrcos, Xrcos[0], Xrcos[1]-Xrcos[0])\n",
    "\n",
    "    lo0mask = lo0mask.reshape(dims[0], dims[1])\n",
    "    resdft = resdft * lo0mask\n",
    "\n",
    "    # residual highpass subband\n",
    "    hi0mask = pointOp(log_rad, Yrcos, Xrcos[0], Xrcos[1]-Xrcos[0])\n",
    "\n",
    "    hi0mask = hi0mask.reshape(resdft.shape[0], resdft.shape[1])\n",
    "    hidft = np.fft.fftshift(np.fft.fft2(pyr_coeffs['residual_highpass']))\n",
    "    resdft += hidft * hi0mask\n",
    "    outresdft = np.real(np.fft.ifft2(np.fft.ifftshift(resdft)))\n",
    "    return outresdft"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
